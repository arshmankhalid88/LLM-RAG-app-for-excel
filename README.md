# LLM-RAG-app-for-excel

This project is a Retrieval-Augmented Generation (RAG) application built with Streamlit, leveraging Llama-3.2 for intelligent querying over Excel files. It uses DoclingReader for document processing and HuggingFace embeddings to enhance data comprehension.

## Features

* Upload .xlsx or .xls files directly.
* Preview Excel data within the app.
* Query your data in natural language using Llama-3.2.
* Real-time chat interface with custom prompts.

# Setup Instructions
## Clone the Repository

```bash
git clone https://github.com/arshmankhalid88/LLM-RAG-app-for-excel.git
cd LLM-RAG-app-for-excel
```

## Create a Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
venv\Scripts\activate  # For Windows
# source venv/bin/activate  # For macOS/Linux
```

## Install Dependencies

```bash
pip install -r requirements.txt
```

If ```requirements.txt``` is missing, manually install the packages:

```bash
pip install streamlit llama-index-core llama-index-readers-docling llama-index-embeddings-huggingface llama-index-llms-ollama pandas
```

## Install and Run Ollama

### Install Ollama

Follow instructions from Ollama's official site.

#### Pull Llama 3.2 Model

```bash
ollama pull llama3.2
```
#### Start Ollama Server

```bash
ollama serve
```

Ensure the server is running on `localhost:11434`.

## Run the Application

```bash
streamlit run "read excel files RAG.py"
```

### How to Use

* Upload an Excel file from the sidebar.
* Once indexed, you'll see a preview of your file.
* Ask questions in natural language (e.g., "What is the total sales in Q1?").
* View responses generated by Llama-3.2.
* Use the "Clear" button to reset the chat history.
  
## Technologies Used

* Streamlit - For building the interactive web app.
* LlamaIndex - To connect LLMs with external data.
* Ollama - For running LLMs locally.
* HuggingFace Embeddings - For enhanced document embeddings.
* DoclingReader - For reading and processing Excel files.

## Troubleshooting

### Port Binding Error
If you see an error like `"bind: Only one usage of each socket address", ensure no other instance of Ollama is running.`

Run the following commands:

```bash
tasklist | findstr ollama
taskkill /PID <PID_NUMBER> /F
```

### Model Not Found

Ensure you've pulled the model using:

```bash
ollama pull llama3.2
```

### Missing Packages
If any imports fail, reinstall the package:

```bash
pip install <missing-package-name>
```

## Future Enhancements
* Add support for PDFs and CSV files.
* Enhance UI with more customization options.
* Deploy on a cloud platform for remote access.

## Acknowledgements
This project was built using open-source tools from the LlamaIndex, Ollama, and HuggingFace communities.

Feel free to fork, modify, and contribute to this project!

